srun -N 1 --ntasks-per-node=2 --mem-per-cpu=8gb -t 02:00:00 -p interactive --pty bash
#tutorial 1 = preprocessing 
module load fastqc
mkdir preprocessing_data

#copy direcotry contents and moved to mine
cp -r /home/knightsd/public/mice5035/2024/host_removed/ /users/7/wrig1125/project/

fastqc -o preprocessing_data /users/7/wrig1125/project/host_removed/*.fastq.gz
#quality is around 30 

module load python/3.6.3
#load in shi7
python3 /home/knightsd/public/shi7/shi7.py -h
#command interface for shi7 because this pathway is where it is located 

python3 /home/knightsd/public/shi7/shi7.py -i /users/7/wrig1125/project/host_removed/ -o preprocessing_data/trimmed_reads -filter_l 100 --combine_fasta False
#trimmed reads to needing at least 100 nucleotides

python3 /home/knightsd/public/shi7/shi7.py -i /users/7/wrig1125/project/host_removed/ -o preprocessing_data/trimmed_reads --filter_qual 30
#quality reads to 30 or above



#making sure it worked 
ls -l preprocessing_data/trimmed_reads 
#SUCCESS YAY

#looking inside the files 
less preprocessing_data/trimmed_reads/shi7.log

#tutorial 2 = 16S feature extraction 
   module load qiime/1.9.1_centos7
   module load bowtie2

cd preprocessing_data/16s-closed-ref/
# new working directory 


grep ">" /users/7/wrig1125/preprocessing_data/trimmed_reads/*.fna | sort | uniq | wc
#output
6551389: The number of unique header lines in the FASTA files.
9892493: The total number of words in the unique headers.
790427502: The total number of characters in the unique headers.

ls /users/7/wrig1125/preprocessing_data/trimmed_reads/*.fna
#verifying the files are there 

#OTU CLOSED reference picking ( most similar ) 
#this code below didnt work and i am so mad ugh
python /home/knightsd/public/mice5035/NINJA-OPS-1.5.1/bin/ninja.py -i /users/7/wrig1125/preprocessing_data/trimmed_reads/*.fna -o otus -p 4 -z -m normal

#trying this 
ls /users/7/wrig1125/preprocessing_data/trimmed_reads/*.fna | grep -v combined_seqs.fna | xargs cat > /users/7/wrig1125/preprocessing_data/trimmed_reads/combined_seqs.fna

mv /users/7/wrig1125/preprocessing_data/trimmed_reads/combined_seqs.fna /users/7/wrig1125/preprocessing_data/
cat /users/7/wrig1125/preprocessing_data/trimmed_reads/*.fna > /users/7/wrig1125/preprocessing_data/trimmed_reads/combined_seqs.fna
mv /users/7/wrig1125/preprocessing_data/combined_seqs.fna /users/7/wrig1125/preprocessing_data/trimmed_reads/

find /users/7/wrig1125/preprocessing_data/trimmed_reads/ -name "*.fna" ! -name "combined_seqs.fna" -exec cat {} + > /users/7/wrig1125/preprocessing_data/trimmed_reads/combined_seqs.fna
ls -lh /users/7/wrig1125/preprocessing_data/trimmed_reads/combined_seqs.fna
#YAY THIS WORKED 

#ran this and it worked ( i used this before the one above and i lowkey like the one above better, sorry ) 
for file in /users/7/wrig1125/preprocessing_data/trimmed_reads/*.fna; do
    python /home/knightsd/public/mice5035/NINJA-OPS-1.5.1/bin/ninja.py -i "$file" -o /users/7/wrig1125/preprocessing_data/otus/ninja -p 4 -z -m normal
done

python /home/knightsd/public/mice5035/NINJA-OPS-1.5.1/bin/ninja.py -i /users/7/wrig1125/preprocessing_data/trimmed_reads/combined_seqs.fna -o /users/7/wrig1125/preprocessing_data/otus -p 4 -z -m normal
#OUTPUT 
Total OTUs available to pick from: 99322
Number of unique samples: 1, max reads: 3198495
Total chimeric alignments: 59
Total reads expanded: 4388
Run complete.
NINJA-OPS parse time: 3.5479735010303557
wrig1125@acn01 [~/preprocessing_data/16s-closed-ref] % 

ls /users/7/wrig1125/preprocessing_data/otus
#made sure the table was in there

#rename folder for consistency with QIIME commands 
mv /users/7/wrig1125/preprocessing_data/otus/ninja_otutable.biom /users/7/wrig1125/preprocessing_data/otus/otutable_2.biom

biom convert -i otus/otutable_2.biom -o otus/otutable_2.txt --to-tsv

head otus/otu_table.txt | cut -f 1-10

wrig1125@acn01 [~/preprocessing_data] % head otus/otu_table.txt | cut -f 1-10
# Constructed from biom file
#OTU ID AllSamps
813944  1.0
752354  1.0
580008  1.0
571905  1.0
567846  1.0
535707  1.0
516022  1.0
484304  1.0


biom summarize-table -i otus/otutable_2.biom -o otus/stats.txt
head -n 30 otus/stats.txt

#output 
wrig1125@acn01 [~/preprocessing_data] % head -n 30 otus/stats.txt
Num samples: 1
Num observations: 2510
Total count: 4388
Table density (fraction of non-zero values): 1.000

Counts/sample summary:
 Min: 4388.000
 Max: 4388.000
 Median: 4388.000
 Mean: 4388.000
 Std. dev.: 0.000
 Sample Metadata Categories: None provided
 Observation Metadata Categories: taxonomy

Counts/sample detail:
AllSamps: 4388.000wrig1125@acn01 [~/preprocessing_data] % 

#rarefy and filter OTU table
single_rarefaction.py -i otus/otutable_2.biom -d 3500 -o otus/otu_table_rarefied.biom

#said i only had one sample so i had to rename them using the command below
awk '{if(NR%2==1) {print ">sample" int(NR/2)+1 "_" substr($0, 2)} else {print $0}}' combined_seqs.fna > combined_seq_with_samples.fna

#rerunning NINJA
python /home/knightsd/public/mice5035/NINJA-OPS-1.5.1/bin/ninja.py -i ~/preprocessing_data/trimmed_reads/combined_seq_with_samples.fna -o ~/preprocessing_data/otus -p 4 -z -m normal

#STILL SAYS I HAVE ONE SAMPLE UGH
