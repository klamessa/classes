srun -N 1 --ntasks-per-node=2 --mem-per-cpu=8gb -t 02:00:00 -p interactive --pty bash
#tutorial 1 = preprocessing 
module load fastqc
mkdir preprocessing_data

#copy direcotry contents and moved to mine
cp -r /home/knightsd/public/mice5035/2024/host_removed/ /users/7/wrig1125/project/

fastqc -o preprocessing_data /users/7/wrig1125/project/host_removed/*.fastq.gz
#quality is around 30 

module load python/3.6.3
#load in shi7
python3 /home/knightsd/public/shi7/shi7.py -h
#command interface for shi7 because this pathway is where it is located 

python3 /home/knightsd/public/shi7/shi7.py -i /users/7/wrig1125/project/host_removed/ -o preprocessing_data/trimmed_reads -filter_l 100 --combine_fasta False
#trimmed reads to needing at least 100 nucleotides

python3 /home/knightsd/public/shi7/shi7.py -i /users/7/wrig1125/project/host_removed/ -o preprocessing_data/trimmed_reads --filter_qual 30
#quality reads to 30 or above



#making sure it worked 
ls -l preprocessing_data/trimmed_reads 
#SUCCESS YAY

#looking inside the files 
less preprocessing_data/trimmed_reads/shi7.log

#tutorial 2 = 16S feature extraction 
   module load qiime/1.9.1_centos7
   module load bowtie2

cd preprocessing_data/16s-closed-ref/
# new working directory 


grep ">" /users/7/wrig1125/preprocessing_data/trimmed_reads/*.fna | sort | uniq | wc
#output
6551389: The number of unique header lines in the FASTA files.
9892493: The total number of words in the unique headers.
790427502: The total number of characters in the unique headers.

ls /users/7/wrig1125/preprocessing_data/trimmed_reads/*.fna
#verifying the files are there 

#OTU CLOSED reference picking ( most similar ) 
#this code below didnt work and i am so mad ugh
python /home/knightsd/public/mice5035/NINJA-OPS-1.5.1/bin/ninja.py -i /users/7/wrig1125/preprocessing_data/trimmed_reads/*.fna -o otus -p 4 -z -m normal

#trying this 
ls /users/7/wrig1125/preprocessing_data/trimmed_reads/*.fna | grep -v combined_seqs.fna | xargs cat > /users/7/wrig1125/preprocessing_data/trimmed_reads/combined_seqs.fna

mv /users/7/wrig1125/preprocessing_data/trimmed_reads/combined_seqs.fna /users/7/wrig1125/preprocessing_data/
cat /users/7/wrig1125/preprocessing_data/trimmed_reads/*.fna > /users/7/wrig1125/preprocessing_data/trimmed_reads/combined_seqs.fna
mv /users/7/wrig1125/preprocessing_data/combined_seqs.fna /users/7/wrig1125/preprocessing_data/trimmed_reads/

find /users/7/wrig1125/preprocessing_data/trimmed_reads/ -name "*.fna" ! -name "combined_seqs.fna" -exec cat {} + > /users/7/wrig1125/preprocessing_data/trimmed_reads/combined_seqs.fna
ls -lh /users/7/wrig1125/preprocessing_data/trimmed_reads/combined_seqs.fna
#YAY THIS WORKED 

#ran this and it worked ( i used this before the one above and i lowkey like the one above better, sorry ) 
for file in /users/7/wrig1125/preprocessing_data/trimmed_reads/*.fna; do
    python /home/knightsd/public/mice5035/NINJA-OPS-1.5.1/bin/ninja.py -i "$file" -o /users/7/wrig1125/preprocessing_data/otus/ninja -p 4 -z -m normal
done

python /home/knightsd/public/mice5035/NINJA-OPS-1.5.1/bin/ninja.py -i /users/7/wrig1125/preprocessing_data/trimmed_reads/combined_seqs.fna -o /users/7/wrig1125/preprocessing_data/otus -p 4 -z -m normal
#OUTPUT 
Total OTUs available to pick from: 99322
Number of unique samples: 1, max reads: 3198495
Total chimeric alignments: 59
Total reads expanded: 4388
Run complete.
NINJA-OPS parse time: 3.5479735010303557
wrig1125@acn01 [~/preprocessing_data/16s-closed-ref] % 

ls /users/7/wrig1125/preprocessing_data/otus
#made sure the table was in there

#rename folder for consistency with QIIME commands 
mv /users/7/wrig1125/preprocessing_data/otus/ninja_otutable.biom /users/7/wrig1125/preprocessing_data/otus/otutable_2.biom

biom convert -i otus/otutable_2.biom -o otus/otutable_2.txt --to-tsv

head otus/otu_table.txt | cut -f 1-10

wrig1125@acn01 [~/preprocessing_data] % head otus/otu_table.txt | cut -f 1-10
# Constructed from biom file
#OTU ID AllSamps
813944  1.0
752354  1.0
580008  1.0
571905  1.0
567846  1.0
535707  1.0
516022  1.0
484304  1.0


biom summarize-table -i otus/otutable_2.biom -o otus/stats.txt
head -n 30 otus/stats.txt

#output 
wrig1125@acn01 [~/preprocessing_data] % head -n 30 otus/stats.txt
Num samples: 1
Num observations: 2510
Total count: 4388
Table density (fraction of non-zero values): 1.000

Counts/sample summary:
 Min: 4388.000
 Max: 4388.000
 Median: 4388.000
 Mean: 4388.000
 Std. dev.: 0.000
 Sample Metadata Categories: None provided
 Observation Metadata Categories: taxonomy

Counts/sample detail:
AllSamps: 4388.000wrig1125@acn01 [~/preprocessing_data] % 

#rarefy and filter OTU table
single_rarefaction.py -i otus/otutable_2.biom -d 3500 -o otus/otu_table_rarefied.biom

#said i only had one sample so i had to rename them using the command below
awk '{if(NR%2==1) {print ">sample" int(NR/2)+1 "_" substr($0, 2)} else {print $0}}' combined_seqs.fna > combined_seq_with_samples.fna

#rerunning NINJA
python /home/knightsd/public/mice5035/NINJA-OPS-1.5.1/bin/ninja.py -i ~/preprocessing_data/trimmed_reads/combined_seq_with_samples.fna -o ~/preprocessing_data/otus -p 4 -z -m normal

#STILL SAYS I HAVE ONE SAMPLE UGH


#LMAO YOU DONT HAVE TO DO THIS ANYWAYS IM CRYING NO WAY ...
#okay anyways im moving on i stg 
#tutorial 3 
module load qiime/1.9.1_centos7
module load kraken
module load bowtie2
module load python/3.6.3

mkdir wgs_kraken 
mkdir kraken_out 

cp -r ~/preprocessing_data/trimmed_reads/*.fna ~/preprocessing_data/wgs_kraken/

#running kraken 
# loop through every .fna file. Run kraken2 on it.
for f in wgs-output/combined_seq_with_samples.fna; do echo $f; time kraken2 --db /home/knightsd/public/minikraken2_v1_8GB --use-mpa-style --output tmp --report kraken-out/`basename $f .fna`.txt --use-names $f; done

ls wgs_kraken/*.fna
#making sure its in this direcotry , it is 

kraken2 --db /home/knightsd/public/minikraken2_v1_8GB --use-mpa-style --output tmp --report kraken-out/test_file.txt --use-names wgs-output/Dance.fa.fna

head -n 20 wgs_kraken/Dance.fa.fna

# just an example of running kraken2 on one individual file:
kraken2 --db /home/knightsd/public/minikraken2_v1_8GB --use-mpa-style --output tmp --report kraken-out/Dance.txt --use-names wgs-output/Dance.fa.fna

for f in trimmed_reads/*.fa.fna; do mv $f trimmed_reads/`basename $f .fa.fna`.fna; done
# loop through every .fna file. Run kraken2 on it.
for f in trimmed_reads/*.fna; do echo $f; time kraken2 --db /home/knightsd/public/minikraken2_v1_8GB --use-mpa-style --output tmp --report kraken-out/`basename $f .fna`.txt --use-names $f; done

# Now we have a single output file per sample;
# we can merge these using the script kraken2table.py in this repo:
wget https://raw.githubusercontent.com/danknights/mice5035/master/scripts/kraken2table.py -O kraken2table.py
python kraken2table.py kraken-out/*.txt taxon_tables

for f in taxon_tables/*.txt; do echo $f; biom convert -i $f --to-json -o `dirname $f`/`basename $f .txt`.biom --process-obs-metadata taxonomy; done

#checking for what depth i should rarefy 
biom summarize-table -i taxon_tables/taxa_table_L7.biom -o stats.txt
less stats.txt

#im going to choose to rarefy at 20,000 depth 
single_rarefaction.py -i taxon_tables/taxa_table_L7.biom -d 20000 -o taxon_tables/taxa_table_L7_rarefied.biom

#run alpha and beta diversity analysis without tree-based metrics 
alpha_diversity.py -m "chao1,observed_otus,shannon" -i taxon_tables/taxa_table_L7_rarefied.biom -o alpha-diversity.txt
beta_diversity.py -i taxon_tables/taxa_table_L7_rarefied.biom -o beta -m "bray_curtis,binary_jaccard"

#run principle coordinates and 3D plots 
principal_coordinates.py -i beta/bray_curtis_taxa_table_L7_rarefied.txt -o beta/bray_curtis_taxa_table_L7_final_pc.txt
principal_coordinates.py -i beta/binary_jaccard_taxa_table_L7_rarefied.txt -o beta/binary_jaccard_taxa_table_L7_final_pc.txt

#getting the metadata mapping file 
cp /home/knightsd/public/mice5035/2024/MICE5035_2024_Fall_class_metadata-v1.txt ~/preprocessing_data/

#make emperor plots
make_emperor.py -i beta/bray_curtis_taxa_table_L7_final_pc.txt -m project_metadata.txt -o 3dplots-bray-curtis
make_emperor.py -i beta/binary_jaccard_taxa_table_L7_final_pc.txt -m project_metadata.txt -o 3dplots-binary-jaccard







